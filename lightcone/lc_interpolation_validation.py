import numpy as np
import pdb
from matplotlib.ticker import FormatStrFormatter
import matplotlib.pyplot as plt
import matplotlib as mpl
from cycler import cycler
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import rcParams
import matplotlib.ticker as plticker
import h5py as h5
import glob

'''
This file contains functions for inspecting and visualizing lightcone output
'''

#######################################
#
#             Utility functions
#
#######################################

def config(cmap): 
    
    rcParams.update({'figure.autolayout': True})
    params = {'text.usetex': False, 'mathtext.fontset': 'stixsans'}
    rcParams.update(params)
    colors = cmap(np.linspace(0.2, 0.8, 3))
    c = cycler('color', colors)
    plt.rcParams["axes.prop_cycle"] = c
    

def plotCube(x, y, z, xw, yw, zw, ax, color, alpha=1):

    xx, yy = np.meshgrid([x, x+xw], [y, y+yw])
    ax.plot_surface(xx, yy, np.ones(np.shape(xx))*z, color=color, alpha=alpha, shade=False)
    ax.plot_surface(xx, yy, np.ones(np.shape(xx))*(z+zw), color=color, alpha=alpha, shade=False)

    yy, zz = np.meshgrid([y, y+yw], [z, z+zw])
    ax.plot_surface(np.ones(np.shape(yy))*x, yy, zz, color=color, alpha=alpha, shade=False)
    ax.plot_surface(np.ones(np.shape(yy))*(x+xw), yy, zz, color=color, alpha=alpha, shade=False)

    zz, xx = np.meshgrid([z, z+zw], [x, x+xw])
    ax.plot_surface(xx, np.ones(np.shape(xx))*y, zz, color=color, alpha=alpha, shade=False)
    ax.plot_surface(xx, np.ones(np.shape(xx))*(y+yw), zz, color=color, alpha=alpha, shade=False)


def downsampleOutput():
    
    from dtk import gio
    from dtk import sort 

    ipath="/home/jphollowed/data/hacc/alphaQ/lightcone/downsampled_particle_intrp_lc/step442"
   
    x = 'x'
    y = 'y'
    z = 'z'

    print("Reading interpolation files")
    iid = gio.gio_read("{}/lc_intrp_output_d.442".format(ipath), 'id')
    ix = gio.gio_read("{}/lc_intrp_output_d.442".format(ipath), x)
    iy = gio.gio_read("{}/lc_intrp_output_d.442".format(ipath), y)
    iz = gio.gio_read("{}/lc_intrp_output_d.442".format(ipath), z)
    irot = gio.gio_read("{}/lc_intrp_output_d.442".format(ipath), 'rotation')
    
    idx = np.linspace(0, len(iid)-1, len(iid), dtype=int)
    randIdx = np.random.choice(idx, size=100000, replace=False)

    ds_iid = iid[randIdx]
    ds_ix = ix[randIdx]
    ds_iy = iy[randIdx]
    ds_iz = iz[randIdx]
    ds_irot = irot[randIdx]

    np.savez('lc_intrp_output_tinySample.npz', id=ds_iid, x=ds_ix, y=ds_iy, 
                                               z=ds_iz,rot=ds_irot)
    return;

#############################################################################################
#############################################################################################

def saveLightconePathData(epath, ipath, spath, outpath, 
                          rL, diffRange='max', posDiffOnly=False):
    '''
    This function loads lightcone output data, and inspects the 
    difference in position resulting from the extrapolation and interpolation
    routines. This difference, per lc object, is called diffVals. It then saves 
    the 3 dimensional paths of 10 of these particles-- either the 10 with the 
    largest diffVals, the median, or minimum-- as .npy files. The results can 
    be viewed as 3d plots by calling plotLightconePaths() below.
    This 3d path includes the true path of the particle from surrounding snapshots, 
    where the particle from the lightcone is matched to the snapshots by id 
    (using descendent/parent ids in the case that the input data is a halo
    lightcone, and merger trees need to be used), and the approximated path
    given by the lightcone solver.
    
    For consistency, the time window used to inspect the objects paths is
    always steps 421 - 464, with step 442 being the one to read lightcone data
    from. It is assumed that the lightcone output directories follow the 
    naming and structure convention given in fig 6 of the Creating Lightcones
    in HACC notes. Snapshot directories are assumed to have a similar structure,
    with subdirectories labeled 'STEPXXX'.
    
    This code is meant to be run on Datastar.

    :param diffRange: whether to use the 'max', 'med'(median) or 'min' diffVals
    :param epath: path to a lightcone output directory generated by the 
                  extrapolation driver
    :param ipath: path to a lightcone output directory generated by the
                  interpolation driver. Should have been run with identical 
                  parameters, on the same cimulation volume, as the run that 
                  generated the data at epath
    :param spath: path to snapshot data from the simulation that was used to 
                  generate the data at epath and ipath
    :param outpath: where to write out the path data (npy files)
    :param rL: the box width of the simulation from which the lightcones at epath
               and ipath were generated, in comoving Mpc/h
    :param posDiffOnly: If true, plot histograms of the position, velocity, and 
                        redshift differences between idnetical objects in the 
                        extrapolation and interpolation outputs. Return after
                        plotting (particle path data won't be output)
    '''
    # do these imports here, since there are other functions in this file that
    # are intended to run on systems where dtk may not be available
    from dtk import gio
    from dtk import sort
    
    subdirs = glob.glob('{}/*'.format(ipath))
    
    # get lc subdirectory prefix (could be 'lc' or 'lcGals', etc.). 
    # prefix of subdirs in epath and ipath assumed to be the same.
    for i in range(len(subdirs[0].split('/')[-1])):
        try:
            (int(subdirs[0].split('/')[-1][i]))
            prefix = subdirs[0].split('/')[-1][0:i]
            break
        except ValueError:
            continue

    # get file names in 442 subdir for interpolated and extrapolated lc data
    # (sort them to grab only the unhashed file header)
    ifile = sorted(glob.glob('{}/{}442/*'.format(ipath, prefix)))[0]
    efile = sorted(glob.glob('{}/{}442/*'.format(epath, prefix)))[0]
   
    # read data
    print("Reading interpolation files")
    iid = gio.gio_read(ifile, 'id')
    ix = gio.gio_read(ifile, 'x')
    iy = gio.gio_read(ifile, 'y')
    iz = gio.gio_read(ifile, 'z')
    ivx = gio.gio_read(ifile, 'vx')
    ivy = gio.gio_read(ifile, 'vy')
    ivz = gio.gio_read(ifile, 'vz')
    ia = gio.gio_read(ifile, 'a')
    irot = gio.gio_read(ifile, 'rotation')

    print("Reading extrapolation files")
    eid = gio.gio_read(efile, 'id')
    ex = gio.gio_read(efile, 'x')
    ey = gio.gio_read(efile, 'y')
    ez = gio.gio_read(efile, 'z')
    evx = gio.gio_read(efile, 'vx')
    evy = gio.gio_read(efile, 'vy')
    evz = gio.gio_read(efile, 'vz')
    ea = gio.gio_read(efile, 'a')
    erot = gio.gio_read(efile, 'rotation')

    # get rid of everything not in the initial volume (don't
    # consider objects found in replicated boxes, since we have
    # no corresponding snapshot data there)
    
    # decrease simulation box side length value by 5% to avoid
    # grabbing objects who originate from some other box replication,
    # but moved into rL by the lightcone position approximation
    rL = rL * 0.99

    initVolMask_interp = np.logical_and.reduce((abs(ix) < rL, 
                                               abs(iy) < rL, 
                                               abs(iz) < rL))
    iid = iid[initVolMask_interp]
    ix = ix[initVolMask_interp]
    iy = iy[initVolMask_interp]
    iz = iz[initVolMask_interp]
    ia = ia[initVolMask_interp]
    irot = irot[initVolMask_interp]

    initVolMask_extrap = np.logical_and.reduce((abs(ex) < rL, 
                                               abs(ey) < rL, 
                                               abs(ez) < rL))
    eid = eid[initVolMask_extrap]
    ex = ex[initVolMask_extrap]
    ey = ey[initVolMask_extrap]
    ez = ez[initVolMask_extrap]
    ea = ea[initVolMask_extrap]
    erot = erot[initVolMask_extrap]

    # make sure that worked...
    if(len(np.unique(irot)) > 1 or len(np.unique(erot)) > 1):
        raise Exception('particles found in replicated boxes >:(')


    # find unique objects to begin matching
    
    print('finding unique')
    iunique = np.unique(iid, return_counts=True)
    eunique = np.unique(eid, return_counts=True)
    if(max(iunique[1]) > 1 or max(eunique[1]) > 1): 
        # There were duplicates found in this volume. pdb trace?
        pass
    
    # get rid of duplicates in interpolation lc data
    iuniqueMask = np.ones(len(iid), dtype=bool)
    iuniqueMask[np.where(np.in1d(iid, iunique[0][iunique[1] > 1]))[0]] = 0

    print('get intersecting data (union of interp and extrap lc objects)')
    intersection_itoe = np.in1d(iid[iuniqueMask], eid)
    intersection_etoi = np.in1d(eid, iid[iuniqueMask])

    print('sorting extrap data array by id to match order of interp data array')
    eSort = np.argsort(eid[intersection_etoi])

    # do binary search using dtk utility to find each object from the interpolation
    # lc data in the extrapolation lc data
    print('matching arrays')
    matchMap = sort.search_sorted(eid[intersection_etoi], 
                                  iid[iuniqueMask][intersection_itoe], sorter=eSort)

    iMask = np.linspace(0, len(iid)-1, len(iid), dtype=int)[iuniqueMask][intersection_itoe]
    eMask = np.linspace(0, len(eid)-1, len(eid), dtype=int)[intersection_etoi][matchMap]

    print('diffing positions')
    xdiff = ix[iMask] - ex[eMask]
    ydiff = iy[iMask] - ey[eMask]
    zdiff = iz[iMask] - ez[eMask]
    posDiff = np.linalg.norm(np.array([xdiff, ydiff, zdiff]).T, axis=1) 
    
    print('diffing velocities')
    vxdiff = ivx[iMask] - evx[eMask]
    vydiff = ivy[iMask] - evy[eMask]
    vzdiff = ivz[iMask] - evz[eMask]
    mag_vDiff = np.linalg.norm(np.array([vxdiff, vydiff, vzdiff]).T, axis=1)
    
    print('diffing redshift')
    redshiftDiff = np.abs(((1/ia)-1)[iMask] - ((1/ea)-1)[eMask])
 
    # plot position, velocity, and redshift differences between interpolated
    # and extrapolated output as historgrams, if posDiffOnly = True
    if(posDiffOnly):
        
        config(cmap=plt.cm.plasma)
        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
        bins = 300
        
        f = plt.figure(0) 
        ax =  f.add_subplot(311)
        ax.hist(posDiff, bins, color=colors[0])
        ax.set_yscale('log')
        ax.set_xlabel(r'$\left|\vec{r}_\mathrm{extrap} - '
                       '\vec{r}_\mathrm{interp}\right|\>\>\mathrm{(Mpc/h)}$', fontsize=18)
        
        ax2 =  f.add_subplot(312)
        ax2.hist(mag_vDiff, bins, color=colors[1])
        ax2.set_yscale('log')
        ax2.set_xlabel(r'$\left|\vec{v}_\mathrm{extrap} - '
                        '\vec{v}_\mathrm{interp}\right| \>\>\mathrm{(km/s)}$', fontsize=18)
        
        ax3 =  f.add_subplot(313)
        ax3.hist(redshiftDiff, bins, color=colors[2])
        ax3.set_yscale('log')
        ax3.set_xlabel(r'$\left|z_\mathrm{extrap} - z_\mathrm{interp}\right|$', fontsize=18)
        
        plt.show()
        return

    # find objects with position differences that are the max, median, or min of 
    # all object differences, depending on the argument given as diffRange. In the
    # case that diffRange='max', for instance, an array diffVals is created that 
    # contains the ten lightcone objects that have the largest difference between 
    # the extrapolation and interpolation solutions. Likewise for diffRange=med and
    # diffRange=min

    print('matching to specified range ({})'.format(diffRange))
    if(diffRange == 'max'):
        diffVals = np.argsort(posDiff)[::-1][0:10]
        savePath = '{}/max_diff'.format(outpath)
    if(diffRange == 'med'):
        diffVals = np.argsort(posDiff)[::-1][len(xdiff)/2:len(xdiff)/2 + 20][0:10]
        savePath = '{}/med_diff'.format(outpath)
    if(diffRange == 'min'):
        diffVals = np.argsort(posDiff)[0:10]
        savePath = '{}/min_diff'.format(outpath)

    # read snapshots...     
    # apply lightcone box rotations to snapshot data
    sx, sy, sz = 'x', 'y', 'z'
    if(irot[0] == 1): 
        sx, sy = 'y', 'x' 
    elif(irot[0] == 2): 
        sy, sz = 'z', 'y'
    elif(irot[0] == 3): 
        sx, sy = 'y', 'x'
        sy, sz = 'z', 'y'
    elif(irot[0] == 4):
        sz, sx = 'x', 'z'
    elif(irot[0] == 5):
        sx, sy = 'y', 'x'
        sz, sx = 'x', 'z'
    
    print("Reading snapshot files")
    sfile0 = sorted(glob.glob('{}/STEP421/*'.format(spath)))[0]
    sid0 = gio.gio_read(sfile0, 'id')
    sx0 = gio.gio_read(sfile0, sx)
    sy0 = gio.gio_read(sfile0, sy)
    sz0 = gio.gio_read(sfile0, sz)
    
    sfile1 = sorted(glob.glob('{}/STEP432/*'.format(spath)))[0]
    sid1 = gio.gio_read(sfile1, 'id')
    sx1 = gio.gio_read(sfile1, sx)
    sy1 = gio.gio_read(sfile1, sy)
    sz1 = gio.gio_read(sfile1, sz)
    
    sfile2 = sorted(glob.glob('{}/STEP442/*'.format(spath)))[0]
    sid2 = gio.gio_read(sfile2, 'id')
    sx2 = gio.gio_read(sfile2, sx)
    sy2 = gio.gio_read(sfile2, sy)
    sz2 = gio.gio_read(sfile2, sz)
    
    sfile3 = sorted(glob.glob('{}/STEP453/*'.format(spath)))[0]
    sid3 = gio.gio_read(sfile3, 'id')
    sx3 = gio.gio_read(sfile3, sx)
    sy3 = gio.gio_read(sfile3, sy)
    sz3 = gio.gio_read(sfile3, sz)
    
    sfile4 = sorted(glob.glob('{}/STEP464/*'.format(spath)))[0]
    sid4 = gio.gio_read(sfile4, 'id')
    sx4 = gio.gio_read(sfile4, sx)
    sy4 = gio.gio_read(sfile4, sy)
    sz4 = gio.gio_read(sfile4, sz)

    # loop through the ten particles selected for plotting, get their surrounding
    # snapshot data, and save the data as .npy files. The results can be plotting 
    # by calling plotLightconePaths() below
    for i in range(len(diffVals)):

        idx = diffVals[i]
        print('Matching to snapshots for idx {} with diff of {}'.format(idx,posDiff[idx]))
        print('Particle ID is {}'.format(iid[iMask][idx]))
        
        # lightcone data
        this_ix = ix[iMask][idx]
        this_iy = iy[iMask][idx]
        this_iz = iz[iMask][idx]
        this_ia = ia[iMask][idx]
        this_irot = irot[iMask][idx]
   
        this_ex = ex[eMask][idx]
        this_ey = ey[eMask][idx]
        this_ez = ez[eMask][idx]
        this_ea = ea[eMask][idx]
        this_erot = erot[iMask][idx]

        # make sure that box rotation for each particle above is the same 
        # (if not, we really screwed up somewhere)
        if(this_irot != this_erot):
            raise Exception('wuuuuuuut why has this happened')

        # snapshot data
        s0_idx = np.where(sid0 == iid[iMask][idx])
        s1_idx = np.where(sid1 == iid[iMask][idx])
        s2_idx = np.where(sid2 == iid[iMask][idx])
        s3_idx = np.where(sid3 == iid[iMask][idx])
        s4_idx = np.where(sid4 == iid[iMask][idx])
      
        sxi0 = sx0[s0_idx][0]
        sxi1 = sx1[s1_idx][0]
        sxi2 = sx2[s2_idx][0]
        sxi3 = sx3[s3_idx][0]
        sxi4 = sx4[s4_idx][0]
        
        syi0 = sy0[s0_idx][0]
        syi1 = sy1[s1_idx][0]
        syi2 = sy2[s2_idx][0]
        syi3 = sy3[s3_idx][0]
        syi4 = sy4[s4_idx][0]
        
        szi0 = sz0[s0_idx][0]
        szi1 = sz1[s1_idx][0]
        szi2 = sz2[s2_idx][0]
        szi3 = sz3[s3_idx][0]
        szi4 = sz4[s4_idx][0]

        # get snapshot scale factors
        aa = np.linspace(1/(1+200), 1, 500)
        sai0 = aa[421]
        sai1 = aa[432]
        sai2 = aa[442]
        sai3 = aa[453]
        sai4 = aa[464]
        
        # true particles path for steps 421-464
        truex = np.array([sxi0, sxi1, sxi2, sxi3, sxi4])
        truey = np.array([syi0, syi1, syi2, syi3, syi4])
        truez = np.array([szi0, szi1, szi2, szi3, szi4])
        truea = np.array([sai0, sai1, sai2, sai3, sai4])
       
        # approximated particle paths for steps 442-453 
        interpolx = np.array([sxi2, this_ix])
        interpoly = np.array([syi2, this_iy])
        interpolz = np.array([szi2, this_iz])
        interpola = np.array([sai2, this_ia])

        extrapx = np.array([sxi2, this_ex])
        extrapy = np.array([syi2, this_ey])
        extrapz = np.array([szi2, this_ez])
        extrapa = np.array([sai2, this_ea])
       
        # done! save particle path data    
        np.save('{}/ix_{}.npy'.format(savePath, i), interpolx)
        np.save('{}/iy_{}.npy'.format(savePath, i), interpoly)
        np.save('{}/iz_{}.npy'.format(savePath, i), interpolz)
        np.save('{}/ia_{}.npy'.format(savePath, i), interpola)
        np.save('{}/iid_{}.npy'.format(savePath, i), iid[iMask][idx])
    
        np.save('{}/ex_{}.npy'.format(savePath, i), extrapx)
        np.save('{}/ey_{}.npy'.format(savePath, i), extrapy)
        np.save('{}/ez_{}.npy'.format(savePath, i), extrapz)
        np.save('{}/ea_{}.npy'.format(savePath, i), extrapa)

        np.save('{}/truex_{}.npy'.format(savePath, i), truex)
        np.save('{}/truey_{}.npy'.format(savePath, i), truey)
        np.save('{}/truez_{}.npy'.format(savePath, i), truez)
        np.save('{}/truea_{}.npy'.format(savePath, i), truea)
        print("saved {} for particle {}".format(diffRange, i))

#############################################################################################
#############################################################################################

def plotLightconePaths(dataPath, diffRange = 'max'):
    '''
    This function plots the 3-dimensional path data as calculated and saved in 
    saveLightconePathData() above.

    :param dataPath: Location of lightcone object path data (should match the outpath
                     argument of saveLightconePathData())
    :param diffRange: whether to use the 'max', 'med'(median) or 'min' diffVals (see 
                      doc strings in saveLightconePathData() for more info)
    '''
    config(cmap=plt.cm.cool)

    # get data files
    data = '{}/{}_diff'.format(dataPath, diffRange)
    numFiles = len(glob.glob('{}/truex_*'.format(data)))

    # loop through all files and plot (each file corresponds to one 
    # lightcone object)
    for i in range(numFiles):

        # read object trajectory data
        ix = np.load('{}/ix_{}.npy'.format(data, i))
        iy = np.load('{}/iy_{}.npy'.format(data, i))
        iz = np.load('{}/iz_{}.npy'.format(data, i))
        ia = np.load('{}/ia_{}.npy'.format(data, i))
        iid = np.load('{}/iid_{}.npy'.format(data, i))
    
        ex = np.load('{}/ex_{}.npy'.format(data, i))
        ey = np.load('{}/ey_{}.npy'.format(data, i))
        ez = np.load('{}/ez_{}.npy'.format(data, i))
        ea = np.load('{}/ea_{}.npy'.format(data, i))
        
        truex = np.load('{}/truex_{}.npy'.format(data, i))
        truey = np.load('{}/truey_{}.npy'.format(data, i))
        truez = np.load('{}/truez_{}.npy'.format(data, i))
        truea = np.load('{}/truea_{}.npy'.format(data, i))

        ax = plt.subplot2grid((3,3), (0,0), rowspan=2, colspan=2, projection='3d')
        x = np.random.randn(10)
        y = np.random.randn(10)
        z = np.random.randn(10)
        
        # ---------- main 3d plot ----------
        # plot true path
        ax.plot(truex, truey, truez, '--k.')
    
        # plot extrapolated and interpolated paths
        ax.plot(ex, ey, ez, '-o', lw=2)
        ax.plot(ix, iy, iz, '-o', lw=2)
        
        # plot star at starting point
        ax.plot([truex[0]], [truey[0]], [truez[0]], '*', ms=10)
        
        # formatting
        plt.title(r'$\mathrm{{ ID }}\>\>{}$'.format(iid), y=1.08, fontsize=18)
        ax.set_xlabel(r'$x\>\>\mathrm{(Mpc/h)}$', fontsize=12, labelpad=12)
        ax.set_ylabel(r'$y\>\>\mathrm{(Mpc/h)}$', fontsize=12, labelpad=12)
        ax.set_zlabel(r'$z\>\>\mathrm{(Mpc/h)}$', fontsize=12, labelpad=12)
        ax.tick_params(axis='both', which='major', labelsize=8)
        for t in range(len(ax.xaxis.get_major_ticks())): 
            if(t%2 == 1): 
                ax.xaxis.get_major_ticks()[t].label.set_color([1, 1, 1]) 
                ax.xaxis.get_major_ticks()[t].label.set_fontsize(0) 
        for t in range(len(ax.yaxis.get_major_ticks())): 
            if(t%2 == 1): 
                ax.yaxis.get_major_ticks()[t].label.set_color([1, 1, 1]) 
                ax.yaxis.get_major_ticks()[t].label.set_fontsize(0) 
        for t in range(len(ax.zaxis.get_major_ticks())): 
            if(t%2 == 1): 
                ax.zaxis.get_major_ticks()[t].label.set_color([1, 1, 1]) 
                ax.zaxis.get_major_ticks()[t].label.set_fontsize(0) 
        
        # ---------- subplot for x-a projection ----------
        ax_xa = plt.subplot2grid((3,3), (2,0), colspan=2)
        
        ax_xa.plot(truex, (1/truea)-1, '--k.')
        ax_xa.plot(ex, (1/ea)-1, '-o', lw=2)
        ax_xa.plot(ix, (1/ia)-1, '-o', lw=2)
        ax_xa.plot(truex[0], (1/truea[0])-1, '*', ms=10)
        
        # formatting
        ax_xa.set_xlabel(r'$x\>\>\mathrm{(Mpc/h)}$', fontsize=14, labelpad=6)
        ax_xa.set_ylabel(r'$\mathrm{redshift}$', fontsize=14, labelpad=6)
        ax_xa.set_yticks((1/truea)-1)
        ax_xa.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))
        ax_xa.yaxis.tick_right()
        ax_xa.yaxis.set_label_position("right")
        ax_xa.invert_yaxis()
        ax_xa.grid()

        # ---------- subplot for z-a projection ----------
        ax_za = plt.subplot2grid((3,3), (0,2), rowspan=2)
        
        ax_za.plot((1/truea)-1, truez, '--k.', label='true dataPath')
        ax_za.plot((1/ea)-1, ez, '-o', lw=2, label = 'extrapolation')
        ax_za.plot((1/ia)-1, iz, '-o', lw=2, label='interpolation') 
        ax_za.plot((1/truea[0])-1, truez[0], '*', ms=10, label='starting position')
        
        # formatting 
        ax_za.set_ylabel(r'$z\>\>\mathrm{(Mpc/h)}$', fontsize=14, labelpad=6)
        ax_za.set_xlabel(r'$\mathrm{redshift}$', fontsize=14, labelpad=6)
        ax_za.set_xticks(1/(truea)-1)
        for tick in ax_za.get_xticklabels(): tick.set_rotation(90)
        ax_za.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))
        ax_za.yaxis.tick_right()
        ax_za.yaxis.set_label_position("right")
        ax_za.grid()

        # legend
        ax_za.legend(bbox_to_anchor=(1.12, -0.35))

        # done
        plt.gcf().set_size_inches(8, 6)
        plt.gcf().tight_layout()
        plt.gcf().canvas.manager.window.move(540, 200)
        plt.show()

#############################################################################################
#############################################################################################

def findDuplicates(lc_type = 'i', dt_type='nonlin'):

    from dtk import sort
    from dtk import gio

    print('reading data')
    if(lc_type == 'i'):
        path1="/home/jphollowed/data/hacc/alphaQ/lightcone/"\
              "downsampled_particle_intrp_lc/step442_{}".format(dt_type)
        path2="/home/jphollowed/data/hacc/alphaQ/lightcone/"\
              "downsampled_particle_intrp_lc/step432_{}".format(dt_type)
        file1 = "{}/lc_intrp_output_d.442".format(path1)
        file2 = "{}/lc_intrp_output_d.432".format(path2)
        outfile = h5.File('dups_interp_{}.hdf5'.format(dt_type), 'w')
    if(lc_type == 'e'):
        path1="/home/jphollowed/data/hacc/alphaQ/lightcone/"\
              "downsampled_particle_extrp_lc/step442_{}".format(dt_type)
        path2="/home/jphollowed/data/hacc/alphaQ/lightcone/"\
              "downsampled_particle_extrp_lc/step432_{}".format(dt_type)
        file1 = "{}/lc_output_d.442".format(path1)
        file2 = "{}/lc_output_d.432".format(path2)
        outfile = h5.File('dups_extrap_{}.hdf5'.format(dt_type), 'w')


    ids1 = gio.gio_read(file1, 'id')
    ids2 = gio.gio_read(file2, 'id')
    
    print('matching')
    matches = sort.search_sorted(ids1, ids2)

    matchesMask2 = matches != -1
    matchesMask1 = matches[matchesMask2]

    print('found {} duplicates'.format(np.sum(matchesMask2)))

    dup_ids1 = ids1[matchesMask1]
    x1 = gio.gio_read(file1, 'x')[matchesMask1]
    y1 = gio.gio_read(file1, 'y')[matchesMask1]
    z1 = gio.gio_read(file1, 'z')[matchesMask1]
    
    dup_ids2 = ids2[matchesMask2]
    x2 = gio.gio_read(file2, 'x')[matchesMask2]
    y2 = gio.gio_read(file2, 'y')[matchesMask2]
    z2 = gio.gio_read(file2, 'z')[matchesMask2]

    repeat_frac = float(len(dup_ids2)) / len(ids2) 
    print('repeat fraction is {}'.format(repeat_frac))

    print('writing out')
    outfile.create_dataset('repeat_frac', data=np.array([repeat_frac]))
    outfile.create_dataset('id', data = np.hstack([dup_ids2, dup_ids1]))
    outfile.create_dataset('x', data = np.hstack([x2, x1]))
    outfile.create_dataset('y', data = np.hstack([y2, y1]))
    outfile.create_dataset('z', data = np.hstack([z2, z1]))

#############################################################################################
#############################################################################################

def compareDuplicates(dt_type = 'linear'):

    path = '/home/joe/gdrive2/work/HEP/data/hacc/alphaQ/lightcone/lc_duplicates'
    idupl = h5.File('{}/dups_interp_{}.hdf5'.format(path, dt_type), 'r')
    edupl = h5.File('{}/dups_extrap_{}.hdf5'.format(path, dt_type), 'r')
    dslc = np.load('lc_intrp_output_tinySample.npz')

    print('Duplicate fraction for old output: {}'.format(edupl['repeat_frac'][:][0]))
    print('Duplicate fraction for new output: {}'.format(idupl['repeat_frac'][:][0]))
    
    f = plt.figure(0)
    axe = f.add_subplot(121, projection='3d')
    axi = f.add_subplot(122, projection='3d')
    plt.suptitle('step 432 - step 442')
    axe.set_title('Extrapolation\nDuplicate fraction: {:.2f}'.format(edupl['repeat_frac'][:][0]))
    axi.set_title('Interpolation\nDuplicate fraction: {:.2E}'.format(idupl['repeat_frac'][:][0]))

    pdb.set_trace()

    maski = np.in1d(idupl['id'], edupl['id'])
    maske = np.in1d(edupl['id'], idupl['id'])
    maske_nokeep = np.random.choice(np.where(~maske)[0], int(len(np.where(~maske)[0])*0.9), replace=False)
    maske[maske_nokeep] = 1
    e_downsample_idx = np.random.choice(np.linspace(0, len(edupl['id'][:])-1, len(edupl['id'][:]), dtype=int), 
                                    int(len(edupl['id'][:])*0.1), replace=False)
    e_downsample = np.zeros(len(edupl['id'][:]), dtype = bool)
    e_downsample[e_downsample_idx] = 1

    #axi.plot(dslc['x'], dslc['y'], dslc['z'], '.y', ms=1)
    #axe.plot(dslc['x'], dslc['y'], dslc['z'], '.y', ms=1)
    
    axe.plot(edupl['x'][e_downsample], edupl['y'][e_downsample], edupl['z'][e_downsample], '.g', ms=1)
    axe.plot(edupl['x'][~maske], edupl['y'][~maske], edupl['z'][~maske], '+m', mew=1)
    axe.set_xlabel('x (Mpc/h)')
    axe.set_ylabel('y (Mpc/h)')
    axe.set_zlabel('y (Mpc/h)')

    axi.plot(idupl['x'], idupl['y'], idupl['z'], '.b', ms=1)
    axi.plot(idupl['x'][~maski], idupl['y'][~maski], idupl['z'][~maski], '+r', mew=1)
    axi.set_xlabel('x (Mpc/h)')
    axi.set_ylabel('y (Mpc/h)')
    axi.set_zlabel('y (Mpc/h)')


    #distMask = np.linalg.norm(np.array([idupl[ax1][:], idupl[ax2][:]]).T, axis=1) < 255
    #print(np.sum(distMask))

    #axi.plot(idupl[ax1][distMask], idupl[ax2][distMask], 'xk', mew=1)
    
    #np.save('weirdIds.npy', idupl['id'][distMask])
    
    #dupl_intrpUnique = np.logical_and(~distMask, ~maski)
    
    #np.save('duplSharedIds.npy', idupl['id'][maski])
    #np.save('dupl_intrpUniqueIds.npy', idupl['id'][dupl_intrpUnique])
    #np.save('dupl_extrpUniqueIds.npy', edupl['id'][~maske])
 
    plt.show()

#############################################################################################
#############################################################################################

def compareReps(dir1, dir2, step):

    f = plt.figure()
    ax1 = f.add_subplot(221, projection='3d')
    ax2 = f.add_subplot(223, projection='3d')
    
    subdirs = glob.glob('{}/*'.format(dir1)) 
    for i in range(len(subdirs[0].split('/')[-1])):
        try:
            (int(subdirs[0].split('/')[-1][i]))
            prefix = subdirs[0].split('/')[-1][0:i]
            break
        except ValueError:
            continue
   
    file1 = sorted(glob.glob("{}/{}{}/*".format(dir1, prefix, step)))[0]
    file2 = sorted(glob.glob("{}/{}{}/*".format(dir2, prefix, step)))[0]

    rot64 = gio.gio_read(file1, 'rotation')
    rep64 = gio.gio_read(file2, 'replication')
    rot256 = gio.gio_read(file1, 'rotation')
    rep256 = gio.gio_read(file2, 'replication')

    uniqRep64 = np.unique(rep64, return_counts=True)
    xReps64 = -((uniqRep64[0] >> 20) - 1) * 256
    yReps64 = -(((uniqRep64[0] >> 10) & 0x3ff) - 1) * 256
    zReps64 = -((uniqRep64[0] & 0x3ff) - 1) * 256

    uniqRep256 = np.unique(rep256, return_counts=True)
    xReps256 = -((uniqRep256[0] >> 20) - 1) * 256
    yReps256 = -(((uniqRep256[0] >> 10) & 0x3ff) - 1) * 256
    zReps256 = -((uniqRep256[0] & 0x3ff) - 1) * 256

    colors = plt.cm.viridis(np.linspace(0, 1, 6))
    for i in range(len(xReps64)):
        plotCube(xReps64[i], yReps64[i], zReps64[i], 256, 256, 256, ax1, colors[xReps64[i]])
        plotCube(xReps256[i], yReps256[i], zReps256[i], 256, 256, 256, ax2, colors[xReps256[i]])

    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_zlabel('z')
    ax2.set_xlabel('x')
    ax2.set_ylabel('y')
    ax2.set_zlabel('z')
    
    plt.show()
